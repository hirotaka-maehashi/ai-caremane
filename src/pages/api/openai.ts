import { NextApiRequest, NextApiResponse } from 'next';
import { createClient } from '@supabase/supabase-js';
import { callOpenAI } from '../../lib/openai';

export default async function handler(req: NextApiRequest, res: NextApiResponse) {
  const token = req.headers.authorization?.replace('Bearer ', '');
  if (!token) {
    console.error('âŒ No token provided');
    return res.status(401).json({ error: 'No token provided' });
  }

  // âœ… Supabaseã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ã€Œtokenä»˜ãã§ã€å†ç”Ÿæˆã™ã‚‹
  const supabase = createClient(
    process.env.NEXT_PUBLIC_SUPABASE_URL!,
    process.env.SUPABASE_SERVICE_ROLE_KEY!,
    {
      global: {
        headers: {
          Authorization: `Bearer ${token}`
        }
      }
    }
  );

  // âœ… ã“ã®å¾Œã« getUser ã‚’å®Ÿè¡Œã™ã‚‹ã“ã¨ã§ token ãŒæ­£ã—ãä½¿ã‚ã‚Œã‚‹
  const { data: { user }, error } = await supabase.auth.getUser();
  if (error || !user) {
    console.error('âŒ Invalid token:', error);
    return res.status(401).json({ error: 'Invalid token' });
  }

  console.log('âœ… user.id:', user.id);

  const { message, industry, model = 'gpt-3.5-turbo' } = req.body;
  if (!message || !industry) {
    console.error('âŒ message ã¾ãŸã¯ industry ãŒä¸è¶³');
    return res.status(400).json({ error: 'Missing message or industry' });
  }

  const { data: keyData } = await supabase
    .from('user_api_keys')
    .select('api_key')
    .eq('user_id', user.id)
    .eq('provider', 'openai')
    .single();

  if (!keyData?.api_key) {
    console.error('âŒ OpenAI APIã‚­ãƒ¼ãŒè¦‹ã¤ã‹ã‚‰ãªã„ï¼ˆuser_api_keysï¼‰');
    return res.status(403).json({ error: 'OpenAI APIã‚­ãƒ¼ãŒã‚ã‚Šã¾ã›ã‚“' });
  }

  console.log('âœ… OpenAI APIã‚­ãƒ¼å–å¾—æˆåŠŸ');

  const { data: limitData } = await supabase
    .from('user_limits')
    .select('token_limit')
    .eq('user_id', user.id)
    .single();

  const { data: usageData } = await supabase
    .from('user_usage')
    .select('used_tokens')
    .eq('user_id', user.id)
    .single();

  const usedTokens = usageData?.used_tokens || 0;
  const maxTokens = limitData?.token_limit || 0;

  console.log(`ğŸ“Š ä½¿ç”¨æ¸ˆã¿ãƒˆãƒ¼ã‚¯ãƒ³: ${usedTokens}, ä¸Šé™: ${maxTokens}`);

  if (usedTokens >= maxTokens) {
    console.error('âŒ ä½¿ç”¨ä¸Šé™ã«é”ã—ã¦ã„ã¾ã™');
    return res.status(403).json({ error: 'ğŸš« ä½¿ç”¨ä¸Šé™ã«é”ã—ã¾ã—ãŸã€‚æœˆé¡åˆ¶é™ã‚’ã”ç¢ºèªãã ã•ã„ã€‚' });
  }

  try {
    console.log('ğŸ“¨ OpenAIå‘¼ã³å‡ºã—é–‹å§‹');
    const { reply, totalTokens } = await callOpenAI(message, keyData.api_key, industry, model);

    console.log(`âœ… OpenAIå‘¼ã³å‡ºã—æˆåŠŸã€ä½¿ç”¨ãƒˆãƒ¼ã‚¯ãƒ³æ•°: ${totalTokens}`);

    await supabase
      .from('user_usage')
      .upsert({
        user_id: user.id,
        used_tokens: usedTokens + totalTokens,
        updated_at: new Date()
      });

    res.status(200).json({ content: reply });
  } catch (err) {
    console.error('âŒ GPTé€šä¿¡ã‚¨ãƒ©ãƒ¼:', err);
    res.status(500).json({ error: 'GPTé€šä¿¡ã‚¨ãƒ©ãƒ¼' });
  }
}
